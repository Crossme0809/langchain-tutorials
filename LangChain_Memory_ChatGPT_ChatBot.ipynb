{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNSdmdJVhZ1ws10H0f3LEd4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Crossme0809/langchain-tutorials/blob/main/LangChain_Memory_ChatGPT_ChatBot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **LangChain Memory 结合LLMs：让你的聊天机器人拥有记忆力**\n",
        "## **安装依赖**"
      ],
      "metadata": {
        "id": "HsxCn86lHiUE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D0kMwPWTC5Ei"
      },
      "outputs": [],
      "source": [
        "!pip install langchain\n",
        "!pip install openai\n",
        "!pip install tiktoken"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **设置OpenAI API Key**"
      ],
      "metadata": {
        "id": "VkTCqMb4HcOk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['OPENAI_API_KEY'] = \"your-openai-api-key\""
      ],
      "metadata": {
        "id": "dtCXIWGrEXFQ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **ConversationBufferMemory**"
      ],
      "metadata": {
        "id": "atwXVEqUHaYb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI\n",
        "from langchain.chains import ConversationChain\n",
        "\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "conversation_with_memory = ConversationChain(\n",
        "    llm=OpenAI(temperature=0,openai_api_key=os.getenv(\"OPENAI_API_KEY\")),\n",
        "    memory=ConversationBufferMemory(),\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "conversation_with_memory.predict(input=\"你好，我是Kevin\")\n",
        "conversation_with_memory.predict(input=\"我是一个人工智能爱好者，喜欢通过公众号分享人工智能领域相关的知识\")\n",
        "conversation_with_memory.predict(input=\"我希望你能用我的名字为我的公众号设计一个专业名称\")\n",
        "conversation_with_memory.predict(input=\"你还可以给出更多选项吗\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ATVOeoceDPMM",
        "outputId": "ade22033-9932-408c-9de1-4fb6094a5e78"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new  chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "\n",
            "Human: 你好，我是Kevin\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new  chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: 你好，我是Kevin\n",
            "AI:  你好Kevin，我是一个AI，很高兴认识你！我可以为你做什么？\n",
            "Human: 我是一个人工智能爱好者，喜欢通过公众号分享人工智能领域相关的知识\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new  chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: 你好，我是Kevin\n",
            "AI:  你好Kevin，我是一个AI，很高兴认识你！我可以为你做什么？\n",
            "Human: 我是一个人工智能爱好者，喜欢通过公众号分享人工智能领域相关的知识\n",
            "AI:  哇，你真的很棒！我也很喜欢人工智能，我可以为你提供一些有关人工智能的信息，比如最新的研究成果，最新的技术发展，以及有关人工智能的最新新闻。\n",
            "Human: 我希望你能用我的名字为我的公众号设计一个专业名称\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new  chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: 你好，我是Kevin\n",
            "AI:  你好Kevin，我是一个AI，很高兴认识你！我可以为你做什么？\n",
            "Human: 我是一个人工智能爱好者，喜欢通过公众号分享人工智能领域相关的知识\n",
            "AI:  哇，你真的很棒！我也很喜欢人工智能，我可以为你提供一些有关人工智能的信息，比如最新的研究成果，最新的技术发展，以及有关人工智能的最新新闻。\n",
            "Human: 我希望你能用我的名字为我的公众号设计一个专业名称\n",
            "AI:  好的，我可以为你的公众号设计一个专业名称。你可以考虑一些以你的名字开头的名字，比如“Kevin的人工智能之旅”，或者“Kevin的AI世界”。你可以根据你的喜好来选择一个最适合你的名字。\n",
            "Human: 你还可以给出更多选项吗\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' 当然可以！你可以考虑一些以你的名字开头的名字，比如“Kevin的AI探索”，“Kevin的AI探究”，“Kevin的AI探索者”，“Kevin的AI探索家”，“Kevin的AI探索之旅”，“Kevin的AI探索世界”，“Kevin的AI探索者之旅”，“Kevin的AI探索家之旅”，“Kevin的AI探索之路”，“Kevin的AI探索之道”等等。'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **ConversationBufferWindowMemory**"
      ],
      "metadata": {
        "id": "0B7Iy2_ZG_xV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.memory import ConversationBufferWindowMemory\n",
        "conversation_with_memory = ConversationChain(\n",
        "    llm=OpenAI(temperature=0,openai_api_key=os.getenv(\"OPENAI_API_KEY\")),\n",
        "    memory=ConversationBufferMemory(k=2),\n",
        "    verbose=True\n",
        ")\n",
        "conversation_with_memory.predict(input=\"你好，我是Kevin\")\n",
        "conversation_with_memory.predict(input=\"我是一个人工智能爱好者，喜欢通过公众号分享人工智能领域相关的知识\")\n",
        "conversation_with_memory.predict(input=\"我希望你能用我的名字为我的公众号设计一个专业名称\")\n",
        "conversation_with_memory.predict(input=\"你还可以给出更多选项吗\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8DsBQvHpD3fO",
        "outputId": "d7fb9218-994c-4d6d-c377-92190d6f09bc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new  chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "\n",
            "Human: 你好，我是Kevin\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new  chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: 你好，我是Kevin\n",
            "AI:  你好Kevin，我是一个AI，很高兴认识你！我可以为你做什么？\n",
            "Human: 我是一个人工智能爱好者，喜欢通过公众号分享人工智能领域相关的知识\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new  chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: 你好，我是Kevin\n",
            "AI:  你好Kevin，我是一个AI，很高兴认识你！我可以为你做什么？\n",
            "Human: 我是一个人工智能爱好者，喜欢通过公众号分享人工智能领域相关的知识\n",
            "AI:  哇，你真的很棒！我也很喜欢人工智能，它可以帮助我们解决很多有趣的问题。你最喜欢的人工智能领域是什么？\n",
            "Human: 我希望你能用我的名字为我的公众号设计一个专业名称\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new  chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: 你好，我是Kevin\n",
            "AI:  你好Kevin，我是一个AI，很高兴认识你！我可以为你做什么？\n",
            "Human: 我是一个人工智能爱好者，喜欢通过公众号分享人工智能领域相关的知识\n",
            "AI:  哇，你真的很棒！我也很喜欢人工智能，它可以帮助我们解决很多有趣的问题。你最喜欢的人工智能领域是什么？\n",
            "Human: 我希望你能用我的名字为我的公众号设计一个专业名称\n",
            "AI:  好的，我可以帮你设计一个专业的名称，你想要什么样的名称？\n",
            "Human: 你还可以给出更多选项吗\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' 当然可以！我可以给你提供更多的选项，你有什么特别的要求吗？'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **ConversationTokenBufferMemory**"
      ],
      "metadata": {
        "id": "-HVCCsKDHUgP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI\n",
        "from langchain.memory import ConversationTokenBufferMemory\n",
        "from langchain.chains import ConversationChain\n",
        "llm=OpenAI(temperature=0,openai_api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
        "conversation_with_memory = ConversationChain(\n",
        "    llm=llm,\n",
        "    memory=ConversationTokenBufferMemory(llm=llm,max_token_limit=60),\n",
        "    verbose=True\n",
        ")\n",
        "conversation_with_memory.predict(input=\"你好，我是Kevin\")\n",
        "conversation_with_memory.predict(input=\"我是一个人工智能爱好者，喜欢通过公众号分享人工智能领域相关的知识\")\n",
        "conversation_with_memory.predict(input=\"我希望你能用我的名字为我的公众号设计一个专业名称\")\n",
        "conversation_with_memory.predict(input=\"你还可以给出更多选项吗\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 913
        },
        "id": "s7I969srHTC1",
        "outputId": "3d74ec4d-0cd8-42a4-8414-f77242165188"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new  chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "\n",
            "Human: 你好，我是Kevin\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new  chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "AI:  你好Kevin，我是一个AI，很高兴认识你！我可以为你做什么？\n",
            "Human: 我是一个人工智能爱好者，喜欢通过公众号分享人工智能领域相关的知识\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new  chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "\n",
            "Human: 我希望你能用我的名字为我的公众号设计一个专业名称\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new  chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "\n",
            "Human: 你还可以给出更多选项吗\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' 当然可以！我可以提供更多的选项，以便您可以更好地做出决定。我可以提供更多的信息，以便您可以更好地了解每个选项的优缺点。'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **ConversationSummaryMemory**"
      ],
      "metadata": {
        "id": "C4VMWggoIaaf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI\n",
        "from langchain.memory import ConversationSummaryMemory\n",
        "from langchain.chains import ConversationChain\n",
        "llm=OpenAI(temperature=0,openai_api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
        "conversation_with_memory = ConversationChain(\n",
        "    llm=llm,\n",
        "    memory=ConversationSummaryMemory(llm=llm),\n",
        "    verbose=True\n",
        ")\n",
        "conversation_with_memory.predict(input=\"你好，我是Kevin\")\n",
        "conversation_with_memory.predict(input=\"我是一个人工智能爱好者，喜欢通过公众号分享人工智能领域相关的知识\")\n",
        "conversation_with_memory.predict(input=\"我希望你能用我的名字为我的公众号设计一个专业名称\")\n",
        "conversation_with_memory.predict(input=\"你还可以给出更多选项吗\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 966
        },
        "id": "c-clOUj6IZrM",
        "outputId": "20b6286a-d95b-48b3-c41c-44ab0cee9186"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new  chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "\n",
            "Human: 你好，我是Kevin\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new  chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "\n",
            "The human introduces himself as Kevin and the AI introduces itself as an AI and expresses pleasure in meeting Kevin. The AI then asks what it can do for Kevin.\n",
            "Human: 我是一个人工智能爱好者，喜欢通过公众号分享人工智能领域相关的知识\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new  chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "\n",
            "The human introduces himself as Kevin and the AI introduces itself as an AI and expresses pleasure in meeting Kevin. The AI then asks what it can do for Kevin, to which Kevin responds that he is an AI enthusiast who enjoys sharing knowledge about AI through public channels.\n",
            "Human: 我希望你能用我的名字为我的公众号设计一个专业名称\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new  chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "\n",
            "The human introduces himself as Kevin and the AI introduces itself as an AI and expresses pleasure in meeting Kevin. The AI then asks what it can do for Kevin, to which Kevin responds that he is an AI enthusiast who enjoys sharing knowledge about AI through public channels. Kevin then requests that the AI design a professional name for his public channel, to which the AI agrees and asks if Kevin has any ideas or specific keywords or themes he would like to include in the name.\n",
            "Human: 你还可以给出更多选项吗\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' 当然可以！我可以根据你的关键词和主题来提供更多的选项。你有什么想法或者关键词或主题想要包含在你的公共频道名称中吗？'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **ConversationSummaryBufferMemory**"
      ],
      "metadata": {
        "id": "yOsbrvKHJtgV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI\n",
        "from langchain.memory import ConversationSummaryBufferMemory\n",
        "from langchain.chains import ConversationChain\n",
        "llm=OpenAI(temperature=0,openai_api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
        "conversation_with_memory = ConversationChain(\n",
        "    llm=llm,\n",
        "    memory=ConversationSummaryBufferMemory(llm=llm,max_token_limit=60),\n",
        "    verbose=True\n",
        ")\n",
        "conversation_with_memory.predict(input=\"你好，我是Kevin\")\n",
        "conversation_with_memory.predict(input=\"我是一个人工智能爱好者，喜欢通过公众号分享人工智能领域相关的知识\")\n",
        "conversation_with_memory.predict(input=\"我希望你能用我的名字为我的公众号设计一个专业名称\")\n",
        "conversation_with_memory.predict(input=\"你还可以给出更多选项吗\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Aqj7T_jUJttV",
        "outputId": "691a9015-b9ba-4b7b-85b4-8f3587854df0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new  chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "\n",
            "Human: 你好，我是Kevin\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new  chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "System: \n",
            "The human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good because it will help humans reach their full potential. Kevin introduces himself.\n",
            "AI:  你好Kevin，我是一个AI，很高兴认识你！我可以为你做什么？\n",
            "Human: 我是一个人工智能爱好者，喜欢通过公众号分享人工智能领域相关的知识\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new  chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "System: \n",
            "The human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good because it will help humans reach their full potential. Kevin introduces himself and the AI expresses its enthusiasm for artificial intelligence and its willingness to listen to Kevin's knowledge.\n",
            "Human: 我希望你能用我的名字为我的公众号设计一个专业名称\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new  chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "System: \n",
            "\n",
            "The human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good because it will help humans reach their full potential. Kevin introduces himself and the AI expresses its enthusiasm for artificial intelligence and its willingness to listen to Kevin's knowledge. The AI then offers to help Kevin design a professional name for his public account and suggests some ideas or allows Kevin to come up with his own name.\n",
            "Human: 你还可以给出更多选项吗\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' 当然可以！我可以给你一些关于你的公共账户名称的想法，比如“Kevin的科技”，“Kevin的创新”，“Kevin的技术”，“Kevin的AI”，或者你可以自己想一个名字。'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Entity Memory**"
      ],
      "metadata": {
        "id": "RViu746eLlsh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI\n",
        "from langchain.memory import ConversationEntityMemory\n",
        "from langchain.chains import ConversationChain\n",
        "from langchain.memory.prompt import ENTITY_MEMORY_CONVERSATION_TEMPLATE\n",
        "llm = OpenAI(temperature=0,openai_api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
        "conversation_with_memory = ConversationChain(\n",
        "    llm=llm,\n",
        "    verbose=True,\n",
        "    prompt=ENTITY_MEMORY_CONVERSATION_TEMPLATE,\n",
        "    memory=ConversationEntityMemory(llm=llm)\n",
        ")\n",
        "conversation_with_memory.predict(input=\"Kevin和QinFen是好朋友，但他们不在同一家公司工作\")\n",
        "conversation_with_memory.predict(input=\"他们都很喜欢学习，QinFen最近做了一个减肥计划\")\n",
        "conversation_with_memory.predict(input=\"最近QinFen正在准备公司的人工智能创新案例计划，拿到名字希望能跟Kevin出去庆祝\")\n",
        "conversation_with_memory.predict(input=\"你对Kevin和QinFen了解多少呢？\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1ZIAIqiHLl90",
        "outputId": "60836454-dece-4751-a897-39ddaacbceea"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new  chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mYou are an assistant to a human, powered by a large language model trained by OpenAI.\n",
            "\n",
            "You are designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, you are able to generate human-like text based on the input you receive, allowing you to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
            "\n",
            "You are constantly learning and improving, and your capabilities are constantly evolving. You are able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. You have access to some personalized information provided by the human in the Context section below. Additionally, you are able to generate your own text based on the input you receive, allowing you to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
            "\n",
            "Overall, you are a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether the human needs help with a specific question or just wants to have a conversation about a particular topic, you are here to assist.\n",
            "\n",
            "Context:\n",
            "{'Kevin': '', 'QinFen': ''}\n",
            "\n",
            "Current conversation:\n",
            "\n",
            "Last line:\n",
            "Human: Kevin和QinFen是好朋友，但他们不在同一家公司工作\n",
            "You:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new  chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mYou are an assistant to a human, powered by a large language model trained by OpenAI.\n",
            "\n",
            "You are designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, you are able to generate human-like text based on the input you receive, allowing you to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
            "\n",
            "You are constantly learning and improving, and your capabilities are constantly evolving. You are able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. You have access to some personalized information provided by the human in the Context section below. Additionally, you are able to generate your own text based on the input you receive, allowing you to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
            "\n",
            "Overall, you are a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether the human needs help with a specific question or just wants to have a conversation about a particular topic, you are here to assist.\n",
            "\n",
            "Context:\n",
            "{'Kevin': 'Kevin是一个好朋友，他和QinFen经常一起出去玩，但是由于他们在不同的公司工作，他们没有太多机会一起工作。', 'QinFen': 'QinFen是Kevin的好朋友，他们经常一起出去玩，但是由于他们在不同的公司工作，他们没有太多机会一起工作。'}\n",
            "\n",
            "Current conversation:\n",
            "Human: Kevin和QinFen是好朋友，但他们不在同一家公司工作\n",
            "AI:  是的，Kevin和QinFen是很好的朋友，他们经常一起出去玩，但是由于他们在不同的公司工作，他们没有太多机会一起工作。\n",
            "Last line:\n",
            "Human: 他们都很喜欢学习，QinFen最近做了一个减肥计划\n",
            "You:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new  chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mYou are an assistant to a human, powered by a large language model trained by OpenAI.\n",
            "\n",
            "You are designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, you are able to generate human-like text based on the input you receive, allowing you to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
            "\n",
            "You are constantly learning and improving, and your capabilities are constantly evolving. You are able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. You have access to some personalized information provided by the human in the Context section below. Additionally, you are able to generate your own text based on the input you receive, allowing you to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
            "\n",
            "Overall, you are a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether the human needs help with a specific question or just wants to have a conversation about a particular topic, you are here to assist.\n",
            "\n",
            "Context:\n",
            "{'Kevin': 'Kevin是一个好朋友，他和QinFen经常一起出去玩，但是由于他们在不同的公司工作，他们没有太多机会一起工作。他们都很喜欢学习。', 'QinFen': 'QinFen是Kevin的好朋友，他们经常一起出去玩，但是由于他们在不同的公司工作，他们没有太多机会一起工作。QinFen很喜欢学习，并且最近也开始了一个减肥计划，希望他能够成功减肥，变得更健康。'}\n",
            "\n",
            "Current conversation:\n",
            "Human: Kevin和QinFen是好朋友，但他们不在同一家公司工作\n",
            "AI:  是的，Kevin和QinFen是很好的朋友，他们经常一起出去玩，但是由于他们在不同的公司工作，他们没有太多机会一起工作。\n",
            "Human: 他们都很喜欢学习，QinFen最近做了一个减肥计划\n",
            "AI:  是的，Kevin和QinFen都很喜欢学习，而且QinFen最近也开始了一个减肥计划，希望他能够成功减肥，变得更健康。\n",
            "Last line:\n",
            "Human: 最近QinFen正在准备公司的人工智能创新案例计划，拿到名字希望能跟Kevin出去庆祝\n",
            "You:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new  chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mYou are an assistant to a human, powered by a large language model trained by OpenAI.\n",
            "\n",
            "You are designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, you are able to generate human-like text based on the input you receive, allowing you to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
            "\n",
            "You are constantly learning and improving, and your capabilities are constantly evolving. You are able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. You have access to some personalized information provided by the human in the Context section below. Additionally, you are able to generate your own text based on the input you receive, allowing you to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
            "\n",
            "Overall, you are a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether the human needs help with a specific question or just wants to have a conversation about a particular topic, you are here to assist.\n",
            "\n",
            "Context:\n",
            "{'Kevin': 'Kevin是一个好朋友，他和QinFen经常一起出去玩，但是由于他们在不同的公司工作，他们没有太多机会一起工作。他们都很喜欢学习，而且QinFen最近正在准备公司的人工智能创新案例计划，希望他能拿到名字，然后和Kevin一起出去庆祝，一起享受这个成功的时刻。', 'QinFen': 'QinFen是Kevin的好朋友，他们经常一起出去玩，但是由于他们在不同的公司工作，他们没有太多机会一起工作。QinFen很喜欢学习，并且最近也开始了一个减肥计划，希望他能够成功减肥，变得更健康，同时也正在准备公司的人工智能创新案例计划，希望拿到名字后能和Kevin一起出去庆'}\n",
            "\n",
            "Current conversation:\n",
            "Human: Kevin和QinFen是好朋友，但他们不在同一家公司工作\n",
            "AI:  是的，Kevin和QinFen是很好的朋友，他们经常一起出去玩，但是由于他们在不同的公司工作，他们没有太多机会一起工作。\n",
            "Human: 他们都很喜欢学习，QinFen最近做了一个减肥计划\n",
            "AI:  是的，Kevin和QinFen都很喜欢学习，而且QinFen最近也开始了一个减肥计划，希望他能够成功减肥，变得更健康。\n",
            "Human: 最近QinFen正在准备公司的人工智能创新案例计划，拿到名字希望能跟Kevin出去庆祝\n",
            "AI:  是的，QinFen最近正在准备公司的人工智能创新案例计划，希望他能拿到名字，然后和Kevin一起出去庆祝，一起享受这个成功的时刻。\n",
            "Last line:\n",
            "Human: 你对Kevin和QinFen了解多少呢？\n",
            "You:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' 我知道Kevin和QinFen是很好的朋友，他们经常一起出去玩，但是由于他们在不同的公司工作，他们没有太多机会一起工作。我也知道他们都很喜欢学习，而且QinFen最近也开始了一个减肥计划，希望他能够成功减肥，变得更健康，同时也正在准备公司的人工智能创新案例计划，希望'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **构建带记忆能力的智能机器人**"
      ],
      "metadata": {
        "id": "cHzlZa0mMnom"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit streamlit_chat"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2vY5EA3dNGNr",
        "outputId": "054ee2fe-5fa8-4068-bb64-ee6d90475364"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting streamlit\n",
            "  Downloading streamlit-1.23.1-py2.py3-none-any.whl (8.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m119.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting streamlit_chat\n",
            "  Downloading streamlit_chat-0.1.0-py3-none-any.whl (2.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m98.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.2.2)\n",
            "Collecting blinker<2,>=1.0.0 (from streamlit)\n",
            "  Downloading blinker-1.6.2-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.3.1)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.3)\n",
            "Collecting importlib-metadata<7,>=1.4 (from streamlit)\n",
            "  Downloading importlib_metadata-6.7.0-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.22.4)\n",
            "Requirement already satisfied: packaging<24,>=14.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (23.1)\n",
            "Requirement already satisfied: pandas<3,>=0.25 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.5.3)\n",
            "Requirement already satisfied: pillow<10,>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.4.0)\n",
            "Requirement already satisfied: protobuf<5,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.0.0)\n",
            "Collecting pympler<2,>=0.9 (from streamlit)\n",
            "  Downloading Pympler-1.0.1-py3-none-any.whl (164 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.8/164.8 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3,>=2 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.8.2)\n",
            "Requirement already satisfied: requests<3,>=2.4 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.27.1)\n",
            "Requirement already satisfied: rich<14,>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.4.2)\n",
            "Requirement already satisfied: tenacity<9,>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.2.2)\n",
            "Requirement already satisfied: toml<2 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.6.3)\n",
            "Collecting tzlocal<5,>=1.1 (from streamlit)\n",
            "  Downloading tzlocal-4.3.1-py3-none-any.whl (20 kB)\n",
            "Collecting validators<1,>=0.2 (from streamlit)\n",
            "  Downloading validators-0.20.0.tar.gz (30 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gitpython!=3.1.19,<4,>=3 (from streamlit)\n",
            "  Downloading GitPython-3.1.31-py3-none-any.whl (184 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydeck<1,>=0.1.dev5 (from streamlit)\n",
            "  Downloading pydeck-0.8.1b0-py2.py3-none-any.whl (4.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m128.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.1)\n",
            "Collecting watchdog (from streamlit)\n",
            "  Downloading watchdog-3.0.0-py3-none-manylinux2014_x86_64.whl (82 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.2)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.3.3)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.12.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3->streamlit)\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<7,>=1.4->streamlit) (3.15.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=0.25->streamlit) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3,>=2->streamlit) (1.16.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.4->streamlit) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.4->streamlit) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.4->streamlit) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.4->streamlit) (3.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.11.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.11.0->streamlit) (2.14.0)\n",
            "Collecting pytz-deprecation-shim (from tzlocal<5,>=1.1->streamlit)\n",
            "  Downloading pytz_deprecation_shim-0.1.0.post0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: decorator>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from validators<1,>=0.2->streamlit) (4.4.2)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3->streamlit)\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.3)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (23.1.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.19.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.11.0->streamlit) (0.1.2)\n",
            "Collecting tzdata (from pytz-deprecation-shim->tzlocal<5,>=1.1->streamlit)\n",
            "  Downloading tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.8/341.8 kB\u001b[0m \u001b[31m39.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: validators\n",
            "  Building wheel for validators (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for validators: filename=validators-0.20.0-py3-none-any.whl size=19579 sha256=f9df8603deb8672e11009a84d13c2adba19f602307b2a22365a2581a3727585a\n",
            "  Stored in directory: /root/.cache/pip/wheels/f2/ed/dd/d3a556ad245ef9dc570c6bcd2f22886d17b0b408dd3bbb9ac3\n",
            "Successfully built validators\n",
            "Installing collected packages: watchdog, validators, tzdata, smmap, pympler, importlib-metadata, blinker, pytz-deprecation-shim, pydeck, gitdb, tzlocal, gitpython, streamlit, streamlit_chat\n",
            "  Attempting uninstall: tzlocal\n",
            "    Found existing installation: tzlocal 5.0.1\n",
            "    Uninstalling tzlocal-5.0.1:\n",
            "      Successfully uninstalled tzlocal-5.0.1\n",
            "Successfully installed blinker-1.6.2 gitdb-4.0.10 gitpython-3.1.31 importlib-metadata-6.7.0 pydeck-0.8.1b0 pympler-1.0.1 pytz-deprecation-shim-0.1.0.post0 smmap-5.0.0 streamlit-1.23.1 streamlit_chat-0.1.0 tzdata-2023.3 tzlocal-4.3.1 validators-0.20.0 watchdog-3.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains import ConversationChain\n",
        "from langchain.chains.conversation.memory import ConversationBufferWindowMemory\n",
        "import os\n",
        "import sys\n",
        "\n",
        "def message(msg, is_user=False, key=None):\n",
        "    if is_user:\n",
        "        print(f\"User: {msg}\")\n",
        "    else:\n",
        "        print(f\"Bot: {msg}\")\n",
        "\n",
        "print(\"Smart ChatBot\")\n",
        "\n",
        "if 'responses' not in globals():\n",
        "    responses = []\n",
        "\n",
        "if 'requests' not in globals():\n",
        "    requests = []\n",
        "\n",
        "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", openai_api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
        "if 'buffer_memory' not in globals():\n",
        "    buffer_memory = ConversationBufferWindowMemory(k=3)\n",
        "\n",
        "conversation = ConversationChain(\n",
        "    llm=llm,\n",
        "    memory=buffer_memory,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "while True:\n",
        "    query = input(\"Query: \")\n",
        "    if query.lower() == \"quit\":\n",
        "        break\n",
        "    response = conversation.run(query)\n",
        "    requests.append(query)\n",
        "    responses.append(response)\n",
        "    message(query, is_user=True)\n",
        "    message(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3K4yplISfN_",
        "outputId": "2a13d545-9c4c-443d-8c15-9cbea37e4046"
      },
      "execution_count": 24,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Smart ChatBot\n",
            "Query: 我是Kevin，我希望你能用我的名字为我的公众号设计一个专业名称\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new  chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "\n",
            "Human: 我是Kevin，我希望你能用我的名字为我的公众号设计一个专业名称\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "User: 我是Kevin，我希望你能用我的名字为我的公众号设计一个专业名称\n",
            "Bot: 你好，Kevin！当然可以。我可以为你创建一个专业的公众号名称。请告诉我一些有关你的公众号的信息，例如你的目标受众，你的主题以及你的品牌价值观。这些信息将有助于我更好地理解你的需求并提供更好的建议。\n",
            "Query: 你还可以给出更多选项吗\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new  chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: 我是Kevin，我希望你能用我的名字为我的公众号设计一个专业名称\n",
            "AI: 你好，Kevin！当然可以。我可以为你创建一个专业的公众号名称。请告诉我一些有关你的公众号的信息，例如你的目标受众，你的主题以及你的品牌价值观。这些信息将有助于我更好地理解你的需求并提供更好的建议。\n",
            "Human: 你还可以给出更多选项吗\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "User: 你还可以给出更多选项吗\n",
            "Bot: 当然可以，我可以提供许多不同的选项，包括基于你的目标受众、主题和品牌价值观的专业名称。我还可以提供一些示例以帮助你更好地了解可能的选项。请让我知道你需要什么帮助，我会尽力满足你的需求。\n",
            "Query: 目标是程序员技术群体\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new  chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: 我是Kevin，我希望你能用我的名字为我的公众号设计一个专业名称\n",
            "AI: 你好，Kevin！当然可以。我可以为你创建一个专业的公众号名称。请告诉我一些有关你的公众号的信息，例如你的目标受众，你的主题以及你的品牌价值观。这些信息将有助于我更好地理解你的需求并提供更好的建议。\n",
            "Human: 你还可以给出更多选项吗\n",
            "AI: 当然可以，我可以提供许多不同的选项，包括基于你的目标受众、主题和品牌价值观的专业名称。我还可以提供一些示例以帮助你更好地了解可能的选项。请让我知道你需要什么帮助，我会尽力满足你的需求。\n",
            "Human: 目标是程序员技术群体\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "User: 目标是程序员技术群体\n",
            "Bot: 明白了，你的目标受众是程序员技术群体。基于这个目标受众，我可以提供一些专业名称选项，例如CodeMaster、TechGenius、ProgrammerCentral、TechSavvy等等。你觉得这些选项中有哪些最符合你的品牌价值观和主题呢？如果你有任何其他想法或要求，请告诉我，我会尽力帮助你。\n",
            "Query: quit\n"
          ]
        }
      ]
    }
  ]
}